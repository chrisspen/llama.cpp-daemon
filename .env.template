# Llama.cpp Server Daemon Template
# Copy this file to .env and modify values as needed

# Service Configuration
SERVICE_USER=%U
SERVICE_GROUP=%g
SERVICE_NAME="llama-server"

# Server Configuration
MODEL_PATH="${MODEL_PATH:-/path/to/model}"
HOST="0.0.0.0"
PORT="8081"
CONTEXT_SIZE="65536"
NGL_LEVEL="99"
JINJA_ENABLED="true"

# Path Configuration
LLAMCPP_DIR="%h/git/llama.cpp"
BUILD_DIR="%h/git/llama.cpp/build/bin"

# Restart Configuration
RESTART_MODE="always"
RESTART_SECONDS="5s"

# Logging
LOG_LEVEL="info"
LOG_PATH="/var/log/llama-server.log"
