# Llama.cpp Server Daemon Template
# Copy this file to .env and modify values as needed

# Service Configuration
SERVICE_USER=$USER
SERVICE_GROUP=$USER
SERVICE_NAME="llama-server"

# Server Configuration
MODEL_PATH="${MODEL_PATH:-/path/to/model}"
HOST="0.0.0.0"
PORT="8081"
CONTEXT_SIZE="32768"
NGL_LEVEL="99"
JINJA_ENABLED="true"

# Path Configuration
LLAMCPP_DIR="${LLAMCPP_DIR:-/path/to/llama.cpp}"
BUILD_DIR="${LLAMCPP_DIR}/build/bin"

# Restart Configuration
RESTART_MODE="always"
RESTART_SECONDS="5s"

# Logging
LOG_LEVEL="info"
LOG_PATH="/var/log/llama-server.log"
